{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Necessary library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install nepali-to-roman\n",
        "%pip install langdetect\n",
        "%pip install pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Input and Output paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load the to-be-tested dataset\n",
        "to_be_tested_dataset_input_path=\"../Facebook Datas/dataset_facebook-comments-scraper_2024-05-03_16-07-42-569.csv\"\n",
        "filtered_dataset_output_path=\"../Profanity and Gender filtered Datas/dataset_facebook-comments-scraper_2024-05-03_16-07-42-569.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Keyword Gathering\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Manual Tagging Profanity Keywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwveRiQtnR2n"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "manual_tagging_df = pd.read_csv(\"./filterwordlist.csv\")\n",
        "manual_tagging_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Checking the number of unique value in Profanity column\n",
        "manual_tagging_df[\"Profanity\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmsA2IyIrtAg",
        "outputId": "8b14eea2-8726-4607-b4ee-93d1603ed46c"
      },
      "outputs": [],
      "source": [
        "# Ensure the 'Profanity' column is treated as strings\n",
        "manual_tagging_df['Profanity'] = manual_tagging_df['Profanity'].astype(str)\n",
        "\n",
        "# Filter the manual_tagging_df DataFrame to get only the rows where the Profanity is '1'\n",
        "manual_profanity_df = manual_tagging_df[manual_tagging_df[\"Profanity\"] == '1']\n",
        "\n",
        "# Reset the index of the manual_profanity_df DataFrame and drop the old index (optional)\n",
        "manual_profanity_df = manual_profanity_df.reset_index(drop=True)\n",
        "\n",
        "# The manual_profanity_df DataFrame now contains only the rows where the Profanity is '1', with a new index\n",
        "manual_profanity_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize an empty set for profanity words\n",
        "profnaity_word_set = set()\n",
        "\n",
        "# Update the profanity word set with the RawNep, RawRom, NormNep, and NormRom columns from the manual_profanity_df DataFrame\n",
        "profnaity_word_set.update(\n",
        "    set(manual_profanity_df[\"RawNep\"]),\n",
        "    set(manual_profanity_df[\"RawRom\"]),\n",
        "    set(manual_profanity_df[\"NormNep\"]),\n",
        "    set(manual_profanity_df[\"NormRom\"])\n",
        ")\n",
        "\n",
        "# The profnaity_word_set set now contains unique profanity words from the RawNep, RawRom, NormNep, and NormRom columns of the manual_profanity_df DataFrame\n",
        "profnaity_word_set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### NepSA Profanity Keywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read the NepSA.csv file into a pandas DataFrame\n",
        "NepSA_df = pd.read_csv(\"./NepSA.csv\", header=None)\n",
        "\n",
        "# Rename the columns of the DataFrame\n",
        "NepSA_df = NepSA_df.rename(columns={1: \"Type\", 2: \"Keyword\", 3: \"Data\"})\n",
        "\n",
        "# Drop the first column of the DataFrame\n",
        "NepSA_df = NepSA_df.drop(columns=[0])\n",
        "\n",
        "# The NepSA_df DataFrame now contains the data from the csv file with the specified column names\n",
        "NepSA_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Checking the number of unique value in Type column\n",
        "NepSA_df[\"Type\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNL2rZ_01P3V",
        "outputId": "d555425b-9fdb-43fb-c3f0-dc42d34b9cb2"
      },
      "outputs": [],
      "source": [
        "# Filter the NepSA_df to get only the rows where the Type is \"PROFANITY\"\n",
        "NepSA_profanity_df = NepSA_df[NepSA_df[\"Type\"]==\"PROFANITY\"]\n",
        "\n",
        "# Create a set of unique profanity keywords from the NepSA_profanity_df\n",
        "NepSaprofane = set(NepSA_profanity_df[\"Keyword\"])\n",
        "NepSaprofane"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cM5x2i6J3uyR",
        "outputId": "b553ca2a-05b3-418b-867a-91bbc4bf8088"
      },
      "outputs": [],
      "source": [
        "# Update the profanity word set with the NepSaprofane set\n",
        "profnaity_word_set.update(NepSaprofane)\n",
        "\n",
        "# Convert the updated profanity word set to a list\n",
        "profnaity_word_list = list(profnaity_word_set)\n",
        "profnaity_word_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculating the total number of profanity words\n",
        "len(profnaity_word_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Profanity filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIlWZDLdt4No",
        "outputId": "4d84e63e-ae9c-425c-b2db-fabedde50856"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Sentences filtering uidng above keywords\n",
        "def profanityfilter(df, column_name, filterwords):\n",
        "    # Create a regex pattern from the filterwords | acts as 'OR' for regex\n",
        "    pattern = '|'.join(filterwords)\n",
        "\n",
        "    # Filter the DataFrame using the regex pattern and specified column\n",
        "    selected_df = df[df[column_name].str.contains(pattern, case=True)]\n",
        "\n",
        "    # Create an empty list to store the results\n",
        "    results = []\n",
        "\n",
        "    # Iterate over the rows of the selected DataFrame\n",
        "    for index, row in selected_df.iterrows():\n",
        "        # Iterate over each filterword\n",
        "        for filterword in filterwords:\n",
        "            # Check if the filterword is present in the row's data\n",
        "            if filterword.lower() in row[column_name].lower():\n",
        "                # Append the row's data and the corresponding filterword to the results list\n",
        "                results.append({column_name: row[column_name], 'Filterword': filterword})\n",
        "                break  # Break out of the inner loop since we found a match\n",
        "\n",
        "    # Convert the results list to a DataFrame\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    return selected_df, results_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Importing to-be-tested Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joEuvIr_0ffL"
      },
      "outputs": [],
      "source": [
        "to_be_tested_dataset=pd.read_csv(to_be_tested_dataset_input_path)\n",
        "to_be_tested_dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Applying the filteration function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filtered_df,result_df= profanityfilter(to_be_tested_dataset,\"text\",profnaity_word_list)\n",
        "filtered_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gender Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Importing files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load boys' names and girls' names from Excel files\n",
        "boys_names_df = pd.read_csv(\"./Boys Names Nepali + Indian - Names.csv\")\n",
        "girls_names_df = pd.read_csv(\"./Girl Name Nepali + Indian - Sheet1.csv\")\n",
        "voter_girls_names_df = pd.read_csv(\"voter_dataset_female.csv\")\n",
        "voter_boys_names_df = pd.read_csv(\"voter_dataset_male.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Labeling, removing duplicate, null values for boys and girls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract only the \"Name\" column and remove rows with missing values\n",
        "boys_names_df = boys_names_df[[\"Name\"]]\n",
        "boys_names_df = boys_names_df.dropna()\n",
        "\n",
        "# Assign a gender label (1 for boys)\n",
        "boys_names_df = boys_names_df.assign(Gender=1)\n",
        "\n",
        "# Split names separated by ';' or '/' and explode into multiple rows\n",
        "boys_names_df['Name'] = boys_names_df['Name'].str.replace(';', ',').replace('/', ',').str.split(',')\n",
        "boys_names_df = boys_names_df.explode('Name')\n",
        "\n",
        "# Assign a gender label (1 for boys)\n",
        "boys_names_df = boys_names_df.assign(Gender=1)\n",
        "boys_names_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For girls' names\n",
        "girls_names_df = girls_names_df[[\"Name\"]]\n",
        "girls_names_df = girls_names_df.dropna()\n",
        "\n",
        "# Split names separated by ';' or '/' and explode into multiple rows\n",
        "girls_names_df['Name'] = girls_names_df['Name'].str.replace(';', ',').replace('/', ',').str.split(',')\n",
        "girls_names_df = girls_names_df.explode('Name')\n",
        "\n",
        "# Assign a gender label (0 for girls)\n",
        "girls_names_df = girls_names_df.assign(Gender=0)\n",
        "girls_names_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "voter_boys_names_df.rename(columns={'First_Name': 'Name'}, inplace=True)\n",
        "voter_boys_names_df = voter_boys_names_df[[\"Name\",\"Gender\"]]\n",
        "voter_boys_names_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "voter_girls_names_df.rename(columns={'First_Name': 'Name'}, inplace=True)\n",
        "voter_girls_names_df = voter_girls_names_df[[\"Name\",\"Gender\"]]\n",
        "voter_girls_names_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Combining all the names in single dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Concatenate boys' and girls' names into one DataFrame\n",
        "combined_names_df = pd.concat([boys_names_df, girls_names_df,voter_boys_names_df,voter_girls_names_df], ignore_index=True)\n",
        "\n",
        "# Remove rows with missing values (NaN) in the \"Name\" column\n",
        "combined_names_df = combined_names_df.dropna(subset=['Name'])\n",
        "\n",
        "# Remove duplicate rows based on the \"Name\" column\n",
        "combined_names_df = combined_names_df.drop_duplicates(subset=['Name'], keep='first')\n",
        "\n",
        "# Reset index\n",
        "combined_names_df = combined_names_df.reset_index(drop=True)\n",
        "\n",
        "# Display the combined DataFrame\n",
        "combined_names_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Conversion of Nepali name into English"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %pip install nepali-to-roman\n",
        "# %pip install langdetect\n",
        "from langdetect import detect\n",
        "import re\n",
        "import ntr\n",
        "\n",
        "def capitalize_after_space(name):\n",
        "    words = name.split()\n",
        "    capitalized_words = [word.capitalize() for word in words]\n",
        "    return ' '.join(capitalized_words)\n",
        "\n",
        "def detect_nep_and_coversion(text):\n",
        "      # Ensure that text is a string or convert it to a string if it's not\n",
        "  if not isinstance(text, str):\n",
        "      text = str(text)\n",
        "  sentences = re.split(r'(?<=[.!?])\\s+(?=\\D)', text)\n",
        "  english_comments = []\n",
        "  for sentence in sentences:\n",
        "      try:\n",
        "          language = detect(sentence)\n",
        "          if language == \"ne\":\n",
        "            sentence=capitalize_after_space(ntr.nep_to_rom(sentence))\n",
        "            english_comments.append(sentence)\n",
        "          else:\n",
        "            english_comments.append(sentence)\n",
        "      except:\n",
        "          pass\n",
        "  filtered_comment = '.'.join(english_comments)\n",
        "  return filtered_comment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filtered_df[\"English_Name\"] = filtered_df[\"profileName\"].apply(detect_nep_and_coversion)\n",
        "filtered_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Detection of Gender using Name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to get gender based on name input\n",
        "def get_gender_from_name(name):\n",
        "    if ' ' in name:\n",
        "        name = name.split(maxsplit=1)[0].capitalize()\n",
        "    else:\n",
        "        name = name.capitalize()\n",
        "    gender = combined_names_df[combined_names_df['Name'] == name]['Gender'].values\n",
        "    if len(gender) > 0:\n",
        "        return gender[0]\n",
        "    else:\n",
        "        return 'Unknown'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filtered_df[\"Gender\"]=filtered_df[\"English_Name\"].apply(get_gender_from_name)\n",
        "filtered_df[[\"English Coversion\",\"NameDetection\"]].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Analysis of Gender Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filtered_df[\"NameDetection\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "filtered_df.groupby('NameDetection').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assuming \"dataset_facebook_comments\" is your DataFrame\n",
        "unknown_names_df = filtered_df[filtered_df[\"NameDetection\"] == \"Unknown\"]\n",
        "\n",
        "# Selecting only the \"profileName\" and \"NameDetection\" columns\n",
        "unknown_names_df = unknown_names_df[[\"profileName\", \"NameDetection\"]]\n",
        "\n",
        "print(unknown_names_df[\"NameDetection\"].value_counts())\n",
        "\n",
        "# Displaying the filtered DataFrame\n",
        "unknown_names_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filtered_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Saving the final Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs(os.path.dirname(filtered_dataset_output_path), exist_ok=True)\n",
        "filtered_df.to_csv(filtered_dataset_output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
